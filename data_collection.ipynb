{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db8b9e7-c50e-4aee-9cad-78e65fc890b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425e5211-062b-4116-975b-da58b96af59d",
   "metadata": {},
   "source": [
    "## 1. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378ce3d9-a47f-4c63-b9fa-9e79769cc535",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollector:\n",
    "    \"\"\"Unified data collection for crypto and traditional assets\"\"\"\n",
    "    \n",
    "    def __init__(self, start_date: str = \"2017-01-01\", end_date: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize data collector\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        start_date : str\n",
    "            Start date in 'YYYY-MM-DD' format\n",
    "        end_date : str, optional\n",
    "            End date in 'YYYY-MM-DD' format (default: today)\n",
    "        \"\"\"\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date or datetime.now().strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Asset universe definition\n",
    "        self.crypto_spot = ['BTC-USD', 'ETH-USD', 'BNB-USD', 'SOL-USD', 'XRP-USD']\n",
    "        self.crypto_memes = ['DOGE-USD', 'SHIB-USD', 'PEPE-USD']\n",
    "        \n",
    "        self.equities = ['^GSPC', '^RUT', 'URTH']  # S&P 500, Russell 2000, MSCI World proxy\n",
    "        self.options = ['^SPX','^PUT'] # SPX\n",
    "        self.bonds = ['AGG', 'IEF', 'TLT']\n",
    "        self.real_estate = ['VNQ']\n",
    "        self.commodities = ['GLD', 'DBC']\n",
    "        self.volatility = ['^VIX']\n",
    "        \n",
    "        self.all_tickers = (self.equities + self.options + self.bonds + self.real_estate + \n",
    "                           self.commodities + self.volatility + self.crypto_spot + self.crypto_memes)\n",
    "        \n",
    "        self.risk_free_rate_ticker = '^IRX'  # 13-week T-bill\n",
    "        \n",
    "    def fetch_yfinance_data(self, tickers: List[str], \n",
    "                           data_type: str = 'Adj Close') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetch data from Yahoo Finance\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        tickers : list\n",
    "            List of ticker symbols\n",
    "        data_type : str\n",
    "            Type of data to fetch ('Adj Close', 'Volume', etc.)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            DataFrame with tickers as columns and dates as index\n",
    "        \"\"\"\n",
    "        print(f\"Fetching {data_type} data for {len(tickers)} tickers...\")\n",
    "        \n",
    "        try:\n",
    "            data = yf.download(\n",
    "                tickers,\n",
    "                start=self.start_date,\n",
    "                end=self.end_date,\n",
    "                progress=False,\n",
    "                auto_adjust=True\n",
    "            )\n",
    "            \n",
    "            if len(tickers) == 1:\n",
    "                result = pd.DataFrame({tickers[0]: data['Close']})\n",
    "            else:\n",
    "                result = data['Close'] if data_type == 'Adj Close' else data[data_type]\n",
    "            \n",
    "            print(f\"✓ Successfully fetched {len(result)} days of data\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error fetching data: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def fetch_all_prices(self) -> pd.DataFrame:\n",
    "        \"\"\"Fetch all asset prices\"\"\"\n",
    "        prices = self.fetch_yfinance_data(self.all_tickers, 'Adj Close')\n",
    "        return prices\n",
    "    \n",
    "    def fetch_all_volumes(self) -> pd.DataFrame:\n",
    "        \"\"\"Fetch all asset volumes\"\"\"\n",
    "        volumes = self.fetch_yfinance_data(self.all_tickers, 'Volume')\n",
    "        return volumes\n",
    "    \n",
    "    def fetch_risk_free_rate(self) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Fetch risk-free rate (13-week T-bill)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.Series\n",
    "            Daily risk-free rate\n",
    "        \"\"\"\n",
    "        print(\"Fetching risk-free rate data...\")\n",
    "        rf_data = yf.download(self.risk_free_rate_ticker, \n",
    "                             start=self.start_date, \n",
    "                             end=self.end_date,\n",
    "                             progress=False)\n",
    "        \n",
    "        # Convert annualized yield to daily\n",
    "        rf_rate = rf_data['Close'] / 100 / 252\n",
    "        return rf_rate\n",
    "    \n",
    "    def clean_and_align_data(self, prices: pd.DataFrame, \n",
    "                            volumes: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Clean and align price and volume data\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        prices : pd.DataFrame\n",
    "            Raw price data\n",
    "        volumes : pd.DataFrame\n",
    "            Raw volume data\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple\n",
    "            (cleaned_prices, cleaned_volumes)\n",
    "        \"\"\"\n",
    "        print(\"\\nCleaning and aligning data...\")\n",
    "        \n",
    "        # Forward fill missing values (max 5 days)\n",
    "        prices_clean = prices.fillna(method='ffill', limit=5)\n",
    "        volumes_clean = volumes.fillna(method='ffill', limit=5)\n",
    "        \n",
    "        # Drop columns with >20% missing data\n",
    "        missing_threshold = 0.20\n",
    "        prices_clean = prices_clean.loc[:, prices_clean.isnull().mean() < missing_threshold]\n",
    "        volumes_clean = volumes_clean.loc[:, volumes_clean.isnull().mean() < missing_threshold]\n",
    "        \n",
    "        # Align on common columns\n",
    "        common_cols = prices_clean.columns.intersection(volumes_clean.columns)\n",
    "        prices_clean = prices_clean[common_cols]\n",
    "        volumes_clean = volumes_clean[common_cols]\n",
    "        \n",
    "        # Drop any remaining rows with NaN\n",
    "        prices_clean = prices_clean.dropna()\n",
    "        volumes_clean = volumes_clean.loc[prices_clean.index]\n",
    "        \n",
    "        print(f\"✓ Clean data: {len(prices_clean)} days, {len(common_cols)} assets\")\n",
    "        print(f\"  Date range: {prices_clean.index[0]} to {prices_clean.index[-1]}\")\n",
    "        \n",
    "        return prices_clean, volumes_clean\n",
    "    \n",
    "    def compute_returns(self, prices: pd.DataFrame, \n",
    "                       method: str = 'log') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Compute returns from prices\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        prices : pd.DataFrame\n",
    "            Price data\n",
    "        method : str\n",
    "            'log' for log returns, 'simple' for simple returns\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            Returns data\n",
    "        \"\"\"\n",
    "        if method == 'log':\n",
    "            returns = np.log(prices / prices.shift(1))\n",
    "        else:\n",
    "            returns = prices.pct_change()\n",
    "        \n",
    "        return returns.dropna()\n",
    "    \n",
    "    def compute_drawdowns(self, prices: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Compute drawdowns for each asset\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        prices : pd.DataFrame\n",
    "            Price data\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            Drawdown series for each asset\n",
    "        \"\"\"\n",
    "        # Compute running maximum\n",
    "        running_max = prices.expanding().max()\n",
    "        \n",
    "        # Compute drawdown\n",
    "        drawdowns = (prices - running_max) / running_max\n",
    "        \n",
    "        return drawdowns\n",
    "    \n",
    "    def get_dataset(self, include_volumes: bool = True) -> Dict:\n",
    "        \"\"\"\n",
    "        Main method to get complete dataset\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        include_volumes : bool\n",
    "            Whether to include volume data\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            Dictionary containing all processed data\n",
    "        \"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"COLLECTING AND PROCESSING DATA\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Fetch data\n",
    "        prices = self.fetch_all_prices()\n",
    "        volumes = self.fetch_all_volumes() if include_volumes else None\n",
    "        rf_rate = self.fetch_risk_free_rate()\n",
    "        \n",
    "        # Clean and align\n",
    "        if include_volumes:\n",
    "            prices_clean, volumes_clean = self.clean_and_align_data(prices, volumes)\n",
    "        else:\n",
    "            prices_clean = prices.dropna()\n",
    "            volumes_clean = None\n",
    "        \n",
    "        # Compute derived metrics\n",
    "        log_returns = self.compute_returns(prices_clean, method='log')\n",
    "        simple_returns = self.compute_returns(prices_clean, method='simple')\n",
    "        drawdowns = self.compute_drawdowns(prices_clean)\n",
    "        \n",
    "        # Align risk-free rate\n",
    "        rf_rate_aligned = rf_rate.reindex(log_returns.index, method='ffill')\n",
    "        \n",
    "        dataset = {\n",
    "            'prices': prices_clean,\n",
    "            'volumes': volumes_clean,\n",
    "            'log_returns': log_returns,\n",
    "            'simple_returns': simple_returns,\n",
    "            'drawdowns': drawdowns,\n",
    "            'risk_free_rate': rf_rate_aligned,\n",
    "            'metadata': {\n",
    "                'start_date': prices_clean.index[0],\n",
    "                'end_date': prices_clean.index[-1],\n",
    "                'n_assets': len(prices_clean.columns),\n",
    "                'n_observations': len(prices_clean),\n",
    "                'assets': prices_clean.columns.tolist()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DATA COLLECTION COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Assets: {dataset['metadata']['n_assets']}\")\n",
    "        print(f\"Observations: {dataset['metadata']['n_observations']}\")\n",
    "        print(f\"Period: {dataset['metadata']['start_date'].date()} to {dataset['metadata']['end_date'].date()}\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        return dataset\n",
    "\n",
    "\n",
    "def save_dataset(dataset: Dict, output_dir: str = './data'):\n",
    "    \"\"\"Save dataset to disk\"\"\"\n",
    "    import os\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    dataset['prices'].to_csv(f'{output_dir}/prices.csv')\n",
    "    dataset['log_returns'].to_csv(f'{output_dir}/log_returns.csv')\n",
    "    dataset['simple_returns'].to_csv(f'{output_dir}/simple_returns.csv')\n",
    "    dataset['drawdowns'].to_csv(f'{output_dir}/drawdowns.csv')\n",
    "    \n",
    "    if dataset['volumes'] is not None:\n",
    "        dataset['volumes'].to_csv(f'{output_dir}/volumes.csv')\n",
    "    \n",
    "    print(f\"✓ Dataset saved to {output_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af29b117-df1b-4afd-8cb3-23ee16a1f373",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2017-01-01\"\n",
    "output_dir = \"result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16a52cf-6997-4c80-9400-aada16802634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Collecting Data\n",
    "\n",
    "collector = DataCollector(start_date = start_date)\n",
    "data = collector.get_dataset()\n",
    "\n",
    "save_dataset(data, output_dir=f\"{output_dir}/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eae856-569a-418e-ba59-ba138160a475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
